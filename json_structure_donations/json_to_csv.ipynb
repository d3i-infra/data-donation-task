{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON file\n",
    "with open('/home/rvissche/Nextcloud/What-If/data/json_structure_donations/Input/json_structure_2_RB_Facebook.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten JSON (handling nested structures)\n",
    "df = pd.json_normalize(data, max_level=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete user specific informations\n",
    "df.columns = df.columns.str.replace(r'^[^/]+/', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract column names\n",
    "cols = df.columns[0:2775]\n",
    "\n",
    "# From wide to long df\n",
    "df = pd.melt(df, value_vars= cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different colums for each part of the document path\n",
    "df['path_1'] = df['variable'].str.split('/', n=1).str[0]\n",
    "df['path_2'] = df['variable'].str.split('/', n=3).str[1]\n",
    "df['path_3'] = df['variable'].str.split('/', n=3).str[2]\n",
    "df['path_4'] = df['variable'].str.split('/', n=3).str[3]\n",
    "\n",
    "# Create a column with the JSON name\n",
    "df['json_name'] = df['variable'].str.rsplit('/', n=1).str[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the JSON name is stored in the json_name column, fill other parts of the path with Na if the name of the JSON is present\n",
    "mark = \".json\"\n",
    "\n",
    "df['path_2'] = df['path_2'].apply(lambda x: np.nan if isinstance(x, str) and mark in x else x)\n",
    "df['path_3'] = df['path_3'].apply(lambda x: np.nan if isinstance(x, str) and mark in x else x)\n",
    "df['path_4'] = df['path_4'].apply(lambda x: np.nan if isinstance(x, str) and mark in x else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlist the value column (where the JSON info is stored)\n",
    "for index, row in df.iterrows():\n",
    "    if isinstance(row['value'], list):\n",
    "        df.at[index, 'value'] = row['value'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an emtpy column for the level 1 JSON \n",
    "df['json_1'] = ''\n",
    "\n",
    "# Extract the level 1 keys\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'json_1'] = list(row['value'].keys())\n",
    "\n",
    "# Take the level 1 keys stored in a list and store them in individual rows\n",
    "df = df.explode('json_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the level 1 keys stored in json_1 extract the level 2 keys and store in json_2\n",
    "df['json_2'] = df.apply(lambda row: [row['value'].get(row['json_1'], None)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlist and store in individual rows\n",
    "df['json_2'] = df['json_2'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "df['json_2'] = df['json_2'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "df = df.explode('json_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data types\n",
    "data_types = ['string', 'array', 'number', 'boolean']\n",
    "\n",
    "# If a data type is stored in json_2 (data types aren't keys) replace with Na and store in the column data_type\n",
    "def process_json_2(row):\n",
    "    if row['json_2'] in data_types:\n",
    "        row['data_type'] = row['json_2']\n",
    "        row['json_2'] = np.nan\n",
    "    return row\n",
    "\n",
    "df = df.apply(process_json_2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns in the df\n",
    "df = df.loc[:, ['variable', 'value', 'path_1', 'path_2',\n",
    "       'path_3', 'path_4', 'json_name', 'json_1', 'json_2', 'data_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-donations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
