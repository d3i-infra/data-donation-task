{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import ast\n",
    "from pathlib import Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"/home/rvissche/Nextcloud/What-If/what-if-data-donation/what-if-data-donation/json_structure_donations/processed_json_structure_donations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data types\n",
    "data_types = ['string', 'array', 'number', 'boolean', 'object']\n",
    "\n",
    "def process_json_2(row):\n",
    "    if row['json_2'] in data_types:\n",
    "        row['data_type'] = row['json_2']\n",
    "        row['json_2'] = np.nan\n",
    "    return row\n",
    "\n",
    "def process_json_3(row):\n",
    "    if row['json_3'] in data_types:\n",
    "        row['data_type'] = row['json_3']\n",
    "        row['json_3'] = np.nan\n",
    "    return row\n",
    "\n",
    "def process_json_4(row):\n",
    "    if row['json_4'] in data_types:\n",
    "        row['data_type'] = row['json_4']\n",
    "        row['json_4'] = np.nan\n",
    "    return row\n",
    "\n",
    "def process_json_5(row):\n",
    "    if row['json_5'] in data_types:\n",
    "        row['data_type'] = row['json_5']\n",
    "        row['json_5'] = np.nan\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "def get_json_3(row):\n",
    "        level1 = row['value'].get(row['json_1'], None)\n",
    "        if isinstance(level1, dict):\n",
    "            return level1.get(row['json_2'], None)\n",
    "        return None\n",
    "\n",
    "def get_json_4(row):\n",
    "        level1 = row['value'].get(row['json_1'], None)\n",
    "        if isinstance(level1, dict):\n",
    "            level2= level1.get(row['json_2'], None)\n",
    "        if isinstance(level2, dict):\n",
    "            return level2.get(row['json_3'], None)\n",
    "        return None\n",
    "\n",
    "def get_json_5(row):\n",
    "        level1 = row['value'].get(row['json_1'], None)\n",
    "        if isinstance(level1, dict):\n",
    "            level2= level1.get(row['json_2'], None)\n",
    "        if isinstance(level2, dict):\n",
    "            level3= level2.get(row['json_3'], None)\n",
    "        if isinstance(level3, dict):\n",
    "            return level3.get(row['json_4'], None)\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def structure_donations(data):\n",
    "\n",
    "    data = Path(data)  \n",
    "    #file_name = data.name  # Extracts \"data.json\"\n",
    "    file_name = Path(data).stem \n",
    "\n",
    "    # Load JSON file\n",
    "    with open(data, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Flatten JSON (handling nested structures)\n",
    "    df = pd.json_normalize(data, max_level=0)\n",
    "\n",
    "    # Delete user specific informations\n",
    "    #df.columns = df.columns.str.replace(r'^[^/]+/', '', regex=True)\n",
    "\n",
    "    # Extract column names\n",
    "    cols = df.columns.tolist()\n",
    "\n",
    "\n",
    "    # From wide to long df\n",
    "    df = pd.melt(df, value_vars= cols)\n",
    "\n",
    "\n",
    "    # Unlist the value column (where the JSON info is stored)\n",
    "    for index, row in df.iterrows():\n",
    "        if isinstance(row['value'], list):\n",
    "            df.at[index, 'value'] = row['value'][0]\n",
    "\n",
    "\n",
    "    # Create an emtpy column for the level 1 JSON \n",
    "    df['json_1'] = ''\n",
    "\n",
    "    # Extract the level 1 keys\n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, 'json_1'] = list(row['value'].keys())\n",
    "\n",
    "    # Take the level 1 keys stored in a list and store them in individual rows\n",
    "    df = df.explode('json_1')\n",
    "\n",
    "    # For the level 1 keys stored in json_1 extract the level 2 keys and store in json_2\n",
    "    df['json_2'] = df.apply(lambda row: [row['value'].get(row['json_1'], None)], axis=1)\n",
    "\n",
    "    # Unlist and store in individual rows\n",
    "    df['json_2'] = df['json_2'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "    df['json_2'] = df['json_2'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "    df = df.explode('json_2')\n",
    "    # If a data type is stored in json_2 (data types aren't keys) replace with Na and store in the column data_type\n",
    "    df = df.apply(process_json_2, axis=1)\n",
    "\n",
    "    #print(df.head())\n",
    "\n",
    "    \n",
    "    #JSON 3\n",
    "    df['json_3'] = df.apply(get_json_3, axis=1)\n",
    "    # Unlist and store in individual rows\n",
    "    df['json_3'] = df['json_3'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "    df = df.explode('json_3')\n",
    "    df = df.apply(process_json_3, axis=1)\n",
    "    \n",
    "    #JSON 4\n",
    "    df['json_4'] = df.apply(get_json_4, axis=1)\n",
    "    # Unlist and store in individual rows\n",
    "    df['json_4'] = df['json_4'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "    df = df.explode('json_4')\n",
    "    df = df.apply(process_json_4, axis=1)\n",
    "\n",
    "    #JSON 5\n",
    "    df['json_5'] = df.apply(get_json_5, axis=1)\n",
    "    # Unlist and store in individual rows\n",
    "    df['json_5'] = df['json_5'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "    df = df.explode('json_5')\n",
    "    df = df.apply(process_json_5, axis=1)\n",
    "\n",
    "     #JSON 6\n",
    "    df['json_6'] = df.apply(get_json_6, axis=1)\n",
    "    # Unlist and store in individual rows\n",
    "    df['json_6'] = df['json_6'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "    df = df.explode('json_6')\n",
    "    df = df.apply(process_json_6, axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Reorder the columns in the df\n",
    "    df = df.loc[:, ['variable', 'value', 'json_1', 'json_2', 'json_3', 'json_4' , 'json_5', 'data_type']]\n",
    "   \n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    dfs = {}\n",
    "    dfs[file_name] = df\n",
    "\n",
    "    df.to_csv(f\"{main_path}TikTok/Output/Output_\" + file_name + '.csv', index=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rvissche/Nextcloud/What-If/what-if-data-donation/what-if-data-donation/json_structure_donations/processed_json_structure_donations/TikTok/Input\n"
     ]
    }
   ],
   "source": [
    "input_directory = Path(f'{main_path}TikTok/Input')  \n",
    "print(input_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rvissche/Nextcloud/What-If/what-if-data-donation/what-if-data-donation/json_structure_donations/processed_json_structure_donations/TikTok/Input/TT_json_structure_MvdV.json\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'level4' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[228]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file.is_file():  \n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mstructure_donations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[226]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mstructure_donations\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     73\u001b[39m df = df.apply(process_json_5, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     75\u001b[39m  \u001b[38;5;66;03m#JSON 6\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mjson_6\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_json_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Unlist and store in individual rows\u001b[39;00m\n\u001b[32m     78\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mjson_6\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mjson_6\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/data-donations/lib/python3.13/site-packages/pandas/core/frame.py:10374\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10360\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10362\u001b[39m op = frame_apply(\n\u001b[32m  10363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10364\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10372\u001b[39m     kwargs=kwargs,\n\u001b[32m  10373\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/data-donations/lib/python3.13/site-packages/pandas/core/apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/data-donations/lib/python3.13/site-packages/pandas/core/apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/data-donations/lib/python3.13/site-packages/pandas/core/apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[225]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mget_json_6\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(level3, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     65\u001b[39m     level4= level3.get(row[\u001b[33m'\u001b[39m\u001b[33mjson_4\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mlevel4\u001b[49m, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m level4.get(row[\u001b[33m'\u001b[39m\u001b[33mjson_5\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'level4' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for file in input_directory.iterdir():  \n",
    "    if file.is_file():  \n",
    "        print(file)\n",
    "        structure_donations(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing CSV files\n",
    "output_path = f\"{main_path}TikTok/Output\"\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = list(Path(output_path).glob(\"*.csv\"))\n",
    "\n",
    "# Load all CSVs into a list of DataFrames\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "\n",
    "common_columns = ['variable', 'value', 'json_name', 'json_1', 'json_2', 'json_3', 'json_4', 'json_5','data_type']\n",
    "\n",
    "merged_df = dfs[0]  # Start with the first DataFrame\n",
    "for df in dfs[1:]:  # Merge with the rest\n",
    "    merged_df = merged_df.merge(df, on=common_columns, how=\"outer\")\n",
    "\n",
    "\"\"\"\n",
    "# Filter where col1 contains 'messages', then drop duplicates based on col2\n",
    "df_filtered = merged_df[merged_df[\"path_1\"] == \"messages\"].drop_duplicates(subset=\"path_2\")\n",
    "\n",
    "\n",
    "# Append rows where col1 does not contain 'messages'\n",
    "df_final = pd.concat([df_filtered, merged_df[merged_df[\"path_1\"] != \"messages\"]], ignore_index=True)\n",
    "\"\"\"\n",
    "\n",
    "# Save the final merged DataFrame\n",
    "merged_df.to_csv(f\"{main_path}TikTok/Final/Merged_structures_TT.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-donations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
